{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.mllib.linalg import Matrices, Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "\n",
    "import numpy as np\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('Python Spark SQL Chi-square test example') \\\n",
    "    .config('spark.executor.memory', '5gb') \\\n",
    "    .config(\"spark.cores.max\", \"6\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a random double RDD that contains 1 million i.i.d. values drawn from the\n",
    "# standard normal distribution `N(0, 1)`, evenly distributed in 10 partitions.\n",
    "n = 1000000\n",
    "x = RandomRDDs.normalRDD(sc, n, 10)\n",
    "stats = x.stats()\n",
    "stats.count()\n",
    "# Apply a transform to get a random double RDD following `N(5, 1)`.\n",
    "mu, sigma = 5, 1 # mean and standard deviation\n",
    "v = x.map(lambda x: mu + sigma * x)\n",
    "stats = v.stats()\n",
    "stats.count()\n",
    "v_min = v.min()\n",
    "v_max = v.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30445431077755547"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.890554969102546"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observed relative frequencies of input data\n",
    "bins_number = 10\n",
    "obs_counts = v.histogram(bins_number)\n",
    "observed = [x / n for x in obs_counts[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.1e-05,\n",
       " 0.00261,\n",
       " 0.03157,\n",
       " 0.159722,\n",
       " 0.344688,\n",
       " 0.315381,\n",
       " 0.123871,\n",
       " 0.020604,\n",
       " 0.001423,\n",
       " 4e-05]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed\n",
    "#type(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theoretical relative frequencies of expected distribution\n",
    "h = (v_max - v_min) / bins_number\n",
    "xi = []\n",
    "\n",
    "for i in range(0,bins_number): xi.append(obs_counts[0][i] + h / 2 )\n",
    "#xi   \n",
    "ti = [(x - mu) / sigma for x in xi]\n",
    "#ti\n",
    "phiti = [(1 / math.sqrt( 2*math.pi )) * math.pow( math.e, -math.pow(x,2) / 2 ) for x in ti]\n",
    "#phiti\n",
    "ni = [(h * n / sigma) * x for x in phiti]\n",
    "#ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.277082583802485e-05,\n",
       " 0.0018973673537105403,\n",
       " 0.027215813081343757,\n",
       " 0.1557412155290475,\n",
       " 0.3555479369816186,\n",
       " 0.3238210844142218,\n",
       " 0.11765880665212952,\n",
       " 0.01705517234557427,\n",
       " 0.0009862798085400004,\n",
       " 2.2753935814106393e-05]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected relative frequencies (expected distribution) of input data\n",
    "expected = [x / n for x in ni]\n",
    "expected\n",
    "#type(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi squared test summary:\n",
      "method: pearson\n",
      "degrees of freedom = 9 \n",
      "statistic = 0.0029182863527482516 \n",
      "pValue = 0.9999999999999967 \n",
      "No presumption against null hypothesis: observed follows the same distribution as expected..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оценим с помощью хи-критерия соответствие распределения\n",
    "#ChiSqTestResult chiSqTest(Vector observed, Vector expected)\n",
    "goodnessOfFitTestResult = Statistics.chiSqTest(Vectors.dense(observed), Vectors.dense(expected))\n",
    "\n",
    "print(\"%s\\n\" % goodnessOfFitTestResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
